{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive Query Execution (AQE) is a feature in Apache Spark that optimizes query execution plans at runtime based on the actual data being processed. This capability allows Spark to make more informed decisions about how to execute queries, potentially leading to significant performance improvements. AQE is particularly useful in scenarios where the data characteristics are not known at compile time, such as when dealing with skewed data or varying data sizes.\n",
    "\n",
    "### Key Concepts of AQE\n",
    "\n",
    "1. **Dynamic Execution Plan**: Unlike traditional query execution where the plan is static and determined before execution, AQE allows Spark to modify the execution plan while the query is running based on real-time statistics.\n",
    "\n",
    "2. **Optimizations**: AQE can apply several optimizations, including:\n",
    "   - **Dynamic Partition Pruning**: Adjusting the partitions that are read based on the data being processed.\n",
    "   - **Coalescing Shuffle Partitions**: Reducing the number of partitions for better performance if the data size is smaller than expected.\n",
    "   - **Skew Join Optimization**: Handling data skew by creating separate execution paths for skewed and non-skewed keys.\n",
    "\n",
    "3. **Statistics Gathering**: During execution, Spark collects statistics about the data, such as the number of rows in a partition or the size of the data being processed. This information is used to make decisions about the execution plan.\n",
    "\n",
    "### Examples of AQE in Action\n",
    "\n",
    "#### Example 1: Dynamic Partition Pruning\n",
    "\n",
    "Consider a scenario where you have two tables,  `orders`  and  `customers` , and you want to join them based on a customer ID. If the  `customers`  table is large, Spark can use AQE to prune unnecessary partitions of the  `orders`  table based on the actual customer IDs present in the  `customers`  table.\n",
    "```\n",
    "# Example Spark SQL query\n",
    "orders_df = spark.table(\"orders\")\n",
    "customers_df = spark.table(\"customers\")\n",
    "\n",
    "result_df = orders_df.join(customers_df, \"customer_id\").filter(customers_df[\"country\"] == \"USA\")\n",
    "```\n",
    "\n",
    "With AQE enabled, Spark will analyze the  `customers_df`  during execution and only read the relevant partitions of  `orders_df` , improving performance by reducing I/O.\n",
    "\n",
    "#### Example 2: Coalescing Shuffle Partitions\n",
    "\n",
    "Imagine you have a large dataset that you are processing, and you expect it to be split into many partitions. However, due to the data characteristics, the actual size of the data is much smaller. With AQE, Spark can dynamically adjust the number of partitions.\n",
    "```\n",
    "# Repartitioning the DataFrame\n",
    "df = spark.read.csv(\"large_dataset.csv\")\n",
    "df = df.repartition(100)  # Initial repartitioning\n",
    "\n",
    "# Perform some transformations\n",
    "result_df = df.groupBy(\"column\").agg({\"value\": \"sum\"})\n",
    "```\n",
    "\n",
    "# AQE can reduce the number of partitions if the data is smaller than expected\n",
    "If AQE is enabled, Spark will monitor the size of  `result_df`  and may reduce the number of partitions from 100 to a smaller number, such as 10, to optimize subsequent processing.\n",
    "\n",
    "#### Example 3: Skew Join Optimization\n",
    "\n",
    "In a scenario where one of the keys in a join operation has a significantly larger number of records (data skew), AQE can help by splitting the join into two separate operations: one for the skewed key and another for the rest.\n",
    "```\n",
    "# Join two DataFrames\n",
    "df1 = spark.read.parquet(\"data1\")\n",
    "df2 = spark.read.parquet(\"data2\")\n",
    "\n",
    "result_df = df1.join(df2, \"key\")\n",
    "```\n",
    "If the  `key`  in  `df2`  has a lot of duplicates, AQE can identify this skew during execution and handle it by creating a separate execution path for the skewed keys, thus improving performance.\n",
    "\n",
    "### Enabling AQE\n",
    "\n",
    "To enable AQE in Spark, you can set the following configurations in your Spark session:\n",
    "```\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")\n",
    "```\n",
    "### Conclusion\n",
    "\n",
    "Adaptive Query Execution is a powerful feature in Apache Spark that enhances the performance of data processing tasks by allowing the execution plan to adapt based on the actual data characteristics. By leveraging AQE, Spark can optimize query execution dynamically, leading to improved efficiency and reduced resource consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32a725944b8810b16d997e1970a86d6a00642d190c49302d97ca631319c2ddf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
